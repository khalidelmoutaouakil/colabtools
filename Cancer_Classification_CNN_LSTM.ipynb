{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cancer_Classification_CNN_LSTM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khalidelmoutaouakil/colabtools/blob/master/Cancer_Classification_CNN_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uaHVunPRjsk",
        "colab_type": "code",
        "outputId": "b9c7c16e-7b32-4452-be54-ba654baa2411",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cbBTzSCbv3Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import division, print_function, absolute_import\n",
        "''' import libraries to disable warnings'''\n",
        "import warnings\n",
        "import logging, os\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "logging.disable(logging.WARNING)\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "\n",
        "''' import all required libraries for data cleansing, preprocessing, training and testing'''\n",
        "from openpyxl import load_workbook\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow as tf\n",
        "from keras.layers import *\n",
        "from keras.models import Model\n",
        "import keras.backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-yglwP6RlHw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "''' Function to get pass the excel sheet location, read every attribute/column,'''\n",
        "def fetch_info(dataset_loc):\n",
        "    def if_int(s):\n",
        "        try:\n",
        "            float(s)\n",
        "            return True\n",
        "        except ValueError:\n",
        "            return False\n",
        "\n",
        "    def ref_change(Ref):\n",
        "        temp = ''\n",
        "        bag_ref = {'A': '1', 'C': '2', 'G': '3', 'T': '4'}\n",
        "        if Ref in bag_ref:\n",
        "            return bag_ref[Ref]\n",
        "        elif Ref == \"-\":\n",
        "            return '0'\n",
        "        else:\n",
        "            for letter in Ref:\n",
        "                if temp == '':\n",
        "                    temp = temp + str(bag_ref[letter])\n",
        "                else:\n",
        "                    temp = temp + ',' + str(bag_ref[letter])\n",
        "            return temp\n",
        "\n",
        "\n",
        "    workbook = load_workbook(dataset_loc,read_only=True)\n",
        "    sheet_1 = workbook.get_sheet_names()[0]\n",
        "    worksheet = workbook.get_sheet_by_name(sheet_1)\n",
        "    FirstRow = True\n",
        "    CancerType_dic = {}\n",
        "    TumorID_dic = {}\n",
        "    GeneName_dic = {}\n",
        "    Chromosome_dic = {}\n",
        "    VariantType_dic = {}\n",
        "    data = []\n",
        "\n",
        "    for row in worksheet.iter_rows():\n",
        "        Row = []\n",
        "        if FirstRow:\n",
        "            FirstRow = False\n",
        "            continue\n",
        "\n",
        "        # CANCER_TYPE\n",
        "        cancerType = str(row[0].value)\n",
        "        if cancerType in CancerType_dic:\n",
        "            Row.append(CancerType_dic[cancerType])\n",
        "        else:\n",
        "            nCancer = len(CancerType_dic)\n",
        "            CancerType_dic[cancerType] = nCancer\n",
        "            Row.append(CancerType_dic[cancerType])\n",
        "\n",
        "        # TUMOR_SAMPLE_ID\n",
        "        tumorID = str(row[1].value)\n",
        "        if tumorID in TumorID_dic:\n",
        "            Row.append(TumorID_dic[tumorID])\n",
        "        else:\n",
        "            nTumorId = len(TumorID_dic)\n",
        "            TumorID_dic[tumorID] = nTumorId + 1\n",
        "            Row.append(TumorID_dic[tumorID])\n",
        "\n",
        "\n",
        "        # GENE_NAME\n",
        "        geneName = str(row[2].value)\n",
        "        if geneName in GeneName_dic:\n",
        "            Row.append(GeneName_dic[geneName])\n",
        "        else:\n",
        "            nGene = len(GeneName_dic)\n",
        "            GeneName_dic[geneName] = nGene + 1\n",
        "            Row.append(GeneName_dic[geneName])\n",
        "\n",
        "\n",
        "        #CHROMOSOME\n",
        "\n",
        "        Chromosome = str(row[3].value)\n",
        "        if if_int(Chromosome):\n",
        "            Row.append(float(Chromosome))\n",
        "        else:\n",
        "            if Chromosome in Chromosome_dic:\n",
        "                Row.append(Chromosome_dic[Chromosome])\n",
        "            else:\n",
        "                nChromo = len(Chromosome_dic)\n",
        "                Chromosome_dic[Chromosome] = (nChromo + 1)*(-1)\n",
        "                Row.append(Chromosome_dic[Chromosome])\n",
        "\n",
        "        #START POSITION\n",
        "\n",
        "        startPos = float(row[4].value)\n",
        "        Row.append(startPos)\n",
        "\n",
        "        #END_POSITION\n",
        "        endPos = float(row[5].value)\n",
        "        Row.append(endPos)\n",
        "\n",
        "        #VARIANT TYPE\n",
        "        variantType = str(row[6].value)\n",
        "        if variantType in VariantType_dic:    #TUMOR_ALLELE\n",
        "\n",
        "            Row.append(VariantType_dic[variantType])\n",
        "        else:\n",
        "            nVariant = len(VariantType_dic)\n",
        "            VariantType_dic[variantType] = nVariant + 1\n",
        "            Row.append(VariantType_dic[variantType])\n",
        "\n",
        "        #REFERENCE_ALLELE\n",
        "        referAllele = row[7].value\n",
        "        Row.append(ref_change(referAllele))\n",
        "\n",
        "        #TUMOR_ALLELE\n",
        "        tumorAlle = row[8].value\n",
        "        Row.append(ref_change(tumorAlle))\n",
        "\n",
        "        data.append(Row)\n",
        "\n",
        "    return np.array(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Re7ij9atcrN4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def dataset_process(data_loc):\n",
        "    def data_scale(data):\n",
        "        min_point = np.min(data)\n",
        "        max_point = np.max(data)\n",
        "\n",
        "        data_norm = (data-min_point)/(max_point - min_point)\n",
        "\n",
        "        return data_norm\n",
        "\n",
        "    def data_seq_padd(feature, maxlen):\n",
        "        features_str = []\n",
        "        n = feature.shape[0]\n",
        "\n",
        "        for i in range(0, n):\n",
        "            x = feature[i]\n",
        "            temp = x.split(\",\")\n",
        "            features_str.append(np.array(temp).astype(int))\n",
        "\n",
        "        int_features = np.array(features_str)\n",
        "        return pad_sequences(int_features, padding='post', maxlen=maxlen)\n",
        "\n",
        "    def featureGen(data):\n",
        "        # generate features\n",
        "\n",
        "        Data = data[:, 0:data.shape[1]-2]\n",
        "        Data = np.array(Data).astype(float)\n",
        "        for i in range(1, data.shape[1] - 2):\n",
        "            Data[:, i] = data_scale(Data[:, i])\n",
        "\n",
        "        # print Data\n",
        "        # features_dict = data[:, 1:6]\n",
        "        Reference_Allele = data[:, 7]\n",
        "        Reference_Allele = data_seq_padd(Reference_Allele, maxlen=96)\n",
        "\n",
        "        Tumor_Allele = data[:, 8]\n",
        "        Tumor_Allele = data_seq_padd(Tumor_Allele, maxlen=82)\n",
        "\n",
        "        y = keras.utils.to_categorical(np.array(Data[:, 0]).astype(int))\n",
        "        x = np.reshape(Data[:, 1:data.shape[1]-2], (-1, 6, 1))\n",
        "        return y, x, Reference_Allele, Tumor_Allele\n",
        "\n",
        "    data = np.load(data_loc)\n",
        "\n",
        "    #SHUFFLE DATA\n",
        "    data = np.take(data, np.random.permutation(data.shape[0]), axis=0, out=data)\n",
        "\n",
        "    # print data\n",
        "\n",
        "    test_values = data.shape[0] - train_values - val_values\n",
        "\n",
        "    train_data = data[0:train_values, :]\n",
        "    valid_data = data[train_values:train_values+val_values, :]\n",
        "    test_data = data[train_values+val_values:, :]\n",
        "\n",
        "    #\n",
        "    [y_train, x_train_feature, x_train_ref, x_train_tumor] = featureGen(train_data)\n",
        "    [y_valid, x_valid_feature, x_valid_ref, x_valid_tumor] = featureGen(valid_data)\n",
        "    [y_test, x_test_feature, x_test_ref, x_test_tumor] = featureGen(test_data)\n",
        "\n",
        "    return (y_train, x_train_feature, x_train_ref, x_train_tumor,\n",
        "            y_valid, x_valid_feature, x_valid_ref, x_valid_tumor,\n",
        "            y_test, x_test_feature, x_test_ref, x_test_tumor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vFB5rK9fYqO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_generate(shapeFeat, shapeRef, shapeTumor, num_class):\n",
        "    # ref LSTM\n",
        "    input_ref = Input(shapeRef, name='ref')\n",
        "\n",
        "    with tf.name_scope('Embedding-Conv1D-LSTM-1'):\n",
        "        ref = Embedding(5, 64, input_length=shapeRef[0])(input_ref)\n",
        "\n",
        "        ref = Conv1D(128, 4, activation='relu')(ref)\n",
        "        ref = MaxPool1D(2)(ref)\n",
        "\n",
        "        ref = LSTM(100)(ref)\n",
        "        ref = Dropout(0.35)(ref)\n",
        "\n",
        "    # tumor LSTM\n",
        "    input_tumor = Input(shapeTumor, name='tumor')\n",
        "\n",
        "    with tf.name_scope('Embedding-Conv1D-LSTM-2'):\n",
        "        tumor = Embedding(5, 64, input_length=shapeTumor[0])(input_tumor)\n",
        "\n",
        "        tumor = Conv1D(128, 4, activation='relu')(tumor)\n",
        "        tumor = MaxPool1D(2)(tumor)\n",
        "\n",
        "        tumor = LSTM(100)(tumor)\n",
        "        tumor = Dropout(0.35)(tumor)\n",
        "\n",
        "    # feature CNN\n",
        "    input_feature = Input(shapeFeat, name='feature')\n",
        "\n",
        "    with tf.name_scope('Conv1D-Dense-3'):\n",
        "        feature = Conv1D(128, 4, activation='relu')(input_feature)\n",
        "        feature = MaxPool1D(2)(feature)\n",
        "\n",
        "        feature = Flatten()(feature)\n",
        "\n",
        "        feature = Dense(100, activation='relu')(feature)\n",
        "        feature = Dropout(0.35)(feature)\n",
        "\n",
        "    # concatenate\n",
        "    cat = concatenate([feature, ref, tumor])\n",
        "\n",
        "    with tf.name_scope('Dense'):\n",
        "        cat = Dense(150, activation='relu')(cat)\n",
        "        cat = Dropout(0.3)(cat)\n",
        "\n",
        "        cat = Dense(50, activation='relu')(cat)\n",
        "        cat = Dropout(0.2)(cat)\n",
        "\n",
        "    outputs = Dense(num_class, activation='softmax', name='logits')(cat)\n",
        "\n",
        "    model = Model(inputs=[input_feature, input_ref, input_tumor],\n",
        "                  outputs=[outputs])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJEwfqjrb0-o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_loc = '/content/drive/My Drive/Colab Notebooks/data/TCGA_Cancer_Dataset_6.xlsx'\n",
        "\n",
        "# Hyper-parameters\n",
        "learning_rate = 1e-4\n",
        "batch_size = 1000\n",
        "epochs = 15\n",
        "train_values = 33000\n",
        "val_values = 1000\n",
        "shapeFeat = (6, 1)\n",
        "shapeRef = (96,)\n",
        "shapeTumor = (82,)\n",
        "total_classes = 6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZW73fJHb_nH",
        "colab_type": "code",
        "outputId": "2659aed9-b582-49af-bdec-0c3db46b18e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "data = fetch_info(dataset_loc)\n",
        "np.save('/content/drive/My Drive/Colab Notebooks/data.npy', data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: DeprecationWarning: Call to deprecated function get_sheet_names (Use wb.sheetnames).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: DeprecationWarning: Call to deprecated function get_sheet_by_name (Use wb[sheetname]).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrFX25AgSpLw",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8i1won4wfJDb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Load data\n",
        "file_path = '/content/drive/My Drive/Colab Notebooks/data.npy'\n",
        "y_train, x_train_feature, x_train_ref, x_train_tumor,\\\n",
        "y_valid, x_valid_feature, x_valid_ref, x_valid_tumor,\\\n",
        "y_test, x_test_feature, x_test_ref, x_test_tumor = dataset_process(file_path)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaS13CNqge5P",
        "colab_type": "code",
        "outputId": "b7965bc7-9842-4cc2-c15f-c95c1fb41154",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        }
      },
      "source": [
        "# Create model\n",
        "model = model_generate(shapeFeat, shapeRef, shapeTumor, total_classes)\n",
        "\n",
        "model = model_generate(shapeFeat, shapeRef, shapeTumor, total_classes)\n",
        "\n",
        "# Compile model with Adam optimizer\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adam(learning_rate),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# call back function\n",
        "cb_ckpt = keras.callbacks.ModelCheckpoint('/content/drive/My Drive/Colab Notebooks/checkpoint/weights.{epoch:05d}-{val_acc:.5f}.h5', monitor='val_acc', verbose=1,\n",
        "                                          save_best_only=True, save_weights_only=False,\n",
        "                                          mode='auto', period=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDZeD5D_hI4U",
        "colab_type": "code",
        "outputId": "117b50df-c08e-41d6-fef9-5dd9400bff60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train model\n",
        "model.fit({'feature': x_train_feature, 'ref': x_train_ref, 'tumor': x_train_tumor},\n",
        "          {'logits': y_train},\n",
        "          shuffle=True, epochs=epochs, batch_size=epochs, callbacks=[cb_ckpt],\n",
        "          validation_data=({'feature': x_valid_feature, 'ref': x_valid_ref, 'tumor': x_valid_tumor},\n",
        "                           {'logits': y_valid}))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 33000 samples, validate on 1000 samples\n",
            "Epoch 1/15\n",
            "33000/33000 [==============================] - 468s 14ms/step - loss: 0.9836 - acc: 0.6437 - val_loss: 0.5962 - val_acc: 0.8230\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.82300, saving model to /content/drive/My Drive/Colab Notebooks/checkpoint/weights.00001-0.82300.h5\n",
            "Epoch 2/15\n",
            "33000/33000 [==============================] - 457s 14ms/step - loss: 0.5306 - acc: 0.8281 - val_loss: 0.4404 - val_acc: 0.8460\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.82300 to 0.84600, saving model to /content/drive/My Drive/Colab Notebooks/checkpoint/weights.00002-0.84600.h5\n",
            "Epoch 3/15\n",
            "33000/33000 [==============================] - 457s 14ms/step - loss: 0.4091 - acc: 0.8588 - val_loss: 0.3527 - val_acc: 0.8650\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.84600 to 0.86500, saving model to /content/drive/My Drive/Colab Notebooks/checkpoint/weights.00003-0.86500.h5\n",
            "Epoch 4/15\n",
            "33000/33000 [==============================] - 457s 14ms/step - loss: 0.3389 - acc: 0.8788 - val_loss: 0.2866 - val_acc: 0.8930\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.86500 to 0.89300, saving model to /content/drive/My Drive/Colab Notebooks/checkpoint/weights.00004-0.89300.h5\n",
            "Epoch 5/15\n",
            "33000/33000 [==============================] - 459s 14ms/step - loss: 0.2846 - acc: 0.8973 - val_loss: 0.2193 - val_acc: 0.9200\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.89300 to 0.92000, saving model to /content/drive/My Drive/Colab Notebooks/checkpoint/weights.00005-0.92000.h5\n",
            "Epoch 6/15\n",
            "33000/33000 [==============================] - 459s 14ms/step - loss: 0.2462 - acc: 0.9102 - val_loss: 0.2015 - val_acc: 0.9230\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.92000 to 0.92300, saving model to /content/drive/My Drive/Colab Notebooks/checkpoint/weights.00006-0.92300.h5\n",
            "Epoch 7/15\n",
            "33000/33000 [==============================] - 452s 14ms/step - loss: 0.2227 - acc: 0.9195 - val_loss: 0.1732 - val_acc: 0.9330\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.92300 to 0.93300, saving model to /content/drive/My Drive/Colab Notebooks/checkpoint/weights.00007-0.93300.h5\n",
            "Epoch 8/15\n",
            "33000/33000 [==============================] - 452s 14ms/step - loss: 0.1974 - acc: 0.9270 - val_loss: 0.1729 - val_acc: 0.9360\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.93300 to 0.93600, saving model to /content/drive/My Drive/Colab Notebooks/checkpoint/weights.00008-0.93600.h5\n",
            "Epoch 9/15\n",
            "33000/33000 [==============================] - 453s 14ms/step - loss: 0.1854 - acc: 0.9313 - val_loss: 0.1418 - val_acc: 0.9480\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.93600 to 0.94800, saving model to /content/drive/My Drive/Colab Notebooks/checkpoint/weights.00009-0.94800.h5\n",
            "Epoch 10/15\n",
            "33000/33000 [==============================] - 454s 14ms/step - loss: 0.1764 - acc: 0.9355 - val_loss: 0.1324 - val_acc: 0.9520\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.94800 to 0.95200, saving model to /content/drive/My Drive/Colab Notebooks/checkpoint/weights.00010-0.95200.h5\n",
            "Epoch 11/15\n",
            "33000/33000 [==============================] - 447s 14ms/step - loss: 0.1656 - acc: 0.9379 - val_loss: 0.1199 - val_acc: 0.9560\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.95200 to 0.95600, saving model to /content/drive/My Drive/Colab Notebooks/checkpoint/weights.00011-0.95600.h5\n",
            "Epoch 12/15\n",
            "33000/33000 [==============================] - 445s 13ms/step - loss: 0.1571 - acc: 0.9410 - val_loss: 0.1031 - val_acc: 0.9610\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.95600 to 0.96100, saving model to /content/drive/My Drive/Colab Notebooks/checkpoint/weights.00012-0.96100.h5\n",
            "Epoch 13/15\n",
            "33000/33000 [==============================] - 448s 14ms/step - loss: 0.1533 - acc: 0.9446 - val_loss: 0.1016 - val_acc: 0.9590\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.96100\n",
            "Epoch 14/15\n",
            "33000/33000 [==============================] - 451s 14ms/step - loss: 0.1458 - acc: 0.9459 - val_loss: 0.1135 - val_acc: 0.9610\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.96100\n",
            "Epoch 15/15\n",
            "33000/33000 [==============================] - 448s 14ms/step - loss: 0.1402 - acc: 0.9485 - val_loss: 0.1228 - val_acc: 0.9590\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.96100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd0879cecf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXuTuTouhPyf",
        "colab_type": "code",
        "outputId": "f6c9a9f4-2b2f-4295-fe3c-03e63d563a2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "results = model.evaluate({'feature': x_train_feature, 'ref': x_train_ref, 'tumor': x_train_tumor},\n",
        "               {'logits': y_train},\n",
        "               verbose=1, batch_size=batch_size)\n",
        "\n",
        "print('Loss: ' + str(results[0]))\n",
        "print('Accuracy: ' + str(results[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "33000/33000 [==============================] - 4s 117us/step\n",
            "Loss: 0.11064044160373283\n",
            "Accuracy: 0.9617272687680793\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xnb-WuGLLrbl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}